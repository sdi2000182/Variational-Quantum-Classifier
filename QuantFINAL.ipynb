{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlmkEMOCPy2I",
        "outputId": "f993be70-2d55-4e55-e13a-a6d233563140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ερώτημα 1"
      ],
      "metadata": {
        "id": "guRdM-vOQAlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    return pd.read_csv(file_path, sep='\\t', header=None)\n",
        "\n",
        "# Load the training and testing data\n",
        "classA_train = load_data(\"/content/gdrive/My Drive/classA_train.dat\")\n",
        "classB_train = load_data(\"/content/gdrive/My Drive/classB_train.dat\")\n",
        "classA_test = load_data(\"/content/gdrive/My Drive/classA_test.dat\")\n",
        "classB_test = load_data(\"/content/gdrive/My Drive/classB_test.dat\")\n",
        "\n",
        "# Label the data\n",
        "classA_train['Label'] = 0\n",
        "classB_train['Label'] = 1\n",
        "classA_test['Label'] = 0\n",
        "classB_test['Label'] = 1"
      ],
      "metadata": {
        "id": "O52DdA66P63O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(classA_train)\n",
        "\n",
        "featuresA= df[[0, 1, 2]].to_numpy()\n",
        "\n",
        "featuresA.shape\n",
        "\n",
        "df = pd.DataFrame(classB_train)\n",
        "\n",
        "featuresB = df[[0, 1, 2]].to_numpy()\n",
        "\n",
        "featuresB.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YQ-jqVTQQZ5",
        "outputId": "af035420-1c1b-4957-a637-b8d7f0ad79a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(classA_train)\n",
        "\n",
        "labelsA = df['Label'].to_numpy()\n",
        "\n",
        "labelsA.shape\n",
        "\n",
        "\n",
        "df = pd.DataFrame(classB_train)\n",
        "\n",
        "labelsB = df['Label'].to_numpy()\n",
        "featuresB.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3lKHm8-QT_s",
        "outputId": "e1d7b38d-ed91-448f-9b51-a3c81db24508"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(classA_test)\n",
        "\n",
        "featuresAT= df[[0, 1, 2]].to_numpy()\n",
        "\n",
        "featuresA.shape\n",
        "\n",
        "df = pd.DataFrame(classB_test)\n",
        "\n",
        "featuresBT = df[[0, 1, 2]].to_numpy()\n",
        "\n",
        "featuresB.shape\n",
        "\n",
        "\n",
        "df = pd.DataFrame(classA_test)\n",
        "\n",
        "labelsAT = df['Label'].to_numpy()\n",
        "\n",
        "labelsA.shape\n",
        "\n",
        "\n",
        "df = pd.DataFrame(classB_test)\n",
        "\n",
        "labelsBT = df['Label'].to_numpy()\n",
        "\n",
        "labelsB.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YojBBLZIQYUW",
        "outputId": "d0378285-beb2-4f7d-8278-bf1b3a738bbf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.concatenate((featuresA, featuresB), axis=0)\n",
        "train_labels = np.concatenate((labelsA, labelsB), axis=0)\n",
        "test_data = np.concatenate((featuresAT, featuresBT), axis=0)\n",
        "test_labels = np.concatenate((labelsAT, labelsBT), axis=0)"
      ],
      "metadata": {
        "id": "Adljsy10Q6eM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pennylane --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6HQSCNLQ8zp",
        "outputId": "40a7ab34-7469-4e91-e8c6-f1e06e3fa328"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.36.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.3)\n",
            "Requirement already satisfied: rustworkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.14.2)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: semantic-version>=2.7 in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.10.0)\n",
            "Requirement already satisfied: autoray>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.6.12)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.3)\n",
            "Requirement already satisfied: pennylane-lightning>=0.36 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.36.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import NesterovMomentumOptimizer\n",
        "\n",
        "# Quantum device with five qubits\n",
        "dev = qml.device(\"lightning.qubit\", wires=3)\n",
        "\n",
        "def layer(layer_weights):\n",
        "    # Arbitrary rotation on each of the five qubits\n",
        "    for wire in range(3):\n",
        "        qml.Rot(*layer_weights[wire], wires=wire)\n",
        "\n",
        "    # Ring of CNOTs for entanglement across all five qubits\n",
        "    for wire_pair in ([0, 1], [1, 2], [2, 0]):\n",
        "        qml.CNOT(wires=wire_pair)\n",
        "\n",
        "def state_preparation(x):\n",
        "    # Applying rotations based on the input x to each qubit\n",
        "    for i, value in enumerate(x):\n",
        "        qml.RY(np.pi * value, wires=i)\n",
        "\n",
        "\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, x):\n",
        "    state_preparation(x)\n",
        "    for layer_weights in weights:\n",
        "        layer(layer_weights)\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias\n",
        "\n",
        "# Accuracy metric\n",
        "def accuracy(labels, predictions):\n",
        "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
        "    return acc / len(labels)\n",
        "\n",
        "def square_loss(labels, predictions):\n",
        "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
        "\n",
        "# Cost function\n",
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)\n",
        "\n",
        "X_train, Y_train = train_data, train_labels\n",
        "Y_train = Y_train * 2 - 1\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "num_qubits = 3\n",
        "num_layers = 2\n",
        "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3)\n",
        "bias_init = np.array(0.0)\n",
        "\n",
        "opt = NesterovMomentumOptimizer(0.5)\n",
        "batch_size = 5\n",
        "\n",
        "weights = weights_init\n",
        "bias = bias_init\n",
        "for it in range(100):\n",
        "    # Update weights and bias using optimizer\n",
        "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "    X_batch = X_train[batch_index]\n",
        "    Y_batch = Y_train[batch_index]\n",
        "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n",
        "\n",
        "    # Compute predictions for the entire training set\n",
        "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_train]\n",
        "    current_cost = cost(weights, bias, X_train, Y_train)\n",
        "    acc = accuracy(Y_train, predictions)\n",
        "\n",
        "    print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")\n",
        "\n",
        "\n",
        "X_test = test_data\n",
        "Y_test = test_labels\n",
        "Y_test = Y_test * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
        "\n",
        "predictions_test = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
        "\n",
        "for x,y,p in zip(X_test, Y_test, predictions_test):\n",
        "    print(f\"x = {x}, y = {y}, pred={p}\")\n",
        "\n",
        "acc_test = accuracy(Y_test, predictions_test)\n",
        "print(\"Accuracy on unseen data:\", acc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmgagIE3Qf1I",
        "outputId": "349c3790-9741-43ae-d786-6cc023735447"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter:    1 | Cost: 2.4714397 | Accuracy: 0.4000000\n",
            "Iter:    2 | Cost: 2.6087861 | Accuracy: 0.4000000\n",
            "Iter:    3 | Cost: 2.5802856 | Accuracy: 0.4000000\n",
            "Iter:    4 | Cost: 2.3958069 | Accuracy: 0.4000000\n",
            "Iter:    5 | Cost: 2.1736472 | Accuracy: 0.5000000\n",
            "Iter:    6 | Cost: 1.0957420 | Accuracy: 0.5000000\n",
            "Iter:    7 | Cost: 1.1368053 | Accuracy: 0.5000000\n",
            "Iter:    8 | Cost: 3.6106683 | Accuracy: 0.5000000\n",
            "Iter:    9 | Cost: 1.5171200 | Accuracy: 0.4250000\n",
            "Iter:   10 | Cost: 0.9411300 | Accuracy: 0.5750000\n",
            "Iter:   11 | Cost: 1.6794954 | Accuracy: 0.6000000\n",
            "Iter:   12 | Cost: 1.1698998 | Accuracy: 0.5000000\n",
            "Iter:   13 | Cost: 1.0560830 | Accuracy: 0.5000000\n",
            "Iter:   14 | Cost: 1.2127564 | Accuracy: 0.5000000\n",
            "Iter:   15 | Cost: 1.0890776 | Accuracy: 0.5000000\n",
            "Iter:   16 | Cost: 1.9395014 | Accuracy: 0.4000000\n",
            "Iter:   17 | Cost: 1.8680441 | Accuracy: 0.4000000\n",
            "Iter:   18 | Cost: 1.9620729 | Accuracy: 0.4000000\n",
            "Iter:   19 | Cost: 1.9646864 | Accuracy: 0.4000000\n",
            "Iter:   20 | Cost: 2.1143730 | Accuracy: 0.5000000\n",
            "Iter:   21 | Cost: 1.2170047 | Accuracy: 0.4750000\n",
            "Iter:   22 | Cost: 1.3535696 | Accuracy: 0.5000000\n",
            "Iter:   23 | Cost: 1.6793151 | Accuracy: 0.5000000\n",
            "Iter:   24 | Cost: 1.4427513 | Accuracy: 0.4500000\n",
            "Iter:   25 | Cost: 1.4749266 | Accuracy: 0.5750000\n",
            "Iter:   26 | Cost: 1.2655390 | Accuracy: 0.5750000\n",
            "Iter:   27 | Cost: 1.8832179 | Accuracy: 0.5000000\n",
            "Iter:   28 | Cost: 1.8888247 | Accuracy: 0.4750000\n",
            "Iter:   29 | Cost: 1.0824978 | Accuracy: 0.5000000\n",
            "Iter:   30 | Cost: 2.5266985 | Accuracy: 0.4750000\n",
            "Iter:   31 | Cost: 0.9461872 | Accuracy: 0.6000000\n",
            "Iter:   32 | Cost: 0.4914018 | Accuracy: 0.9500000\n",
            "Iter:   33 | Cost: 1.8945768 | Accuracy: 0.5000000\n",
            "Iter:   34 | Cost: 1.2007079 | Accuracy: 0.4500000\n",
            "Iter:   35 | Cost: 0.8252067 | Accuracy: 0.6250000\n",
            "Iter:   36 | Cost: 0.6412700 | Accuracy: 0.8000000\n",
            "Iter:   37 | Cost: 1.5253094 | Accuracy: 0.4000000\n",
            "Iter:   38 | Cost: 1.0721480 | Accuracy: 0.5000000\n",
            "Iter:   39 | Cost: 0.8917160 | Accuracy: 0.6750000\n",
            "Iter:   40 | Cost: 1.1944581 | Accuracy: 0.5750000\n",
            "Iter:   41 | Cost: 0.9557919 | Accuracy: 0.5500000\n",
            "Iter:   42 | Cost: 1.1056955 | Accuracy: 0.5750000\n",
            "Iter:   43 | Cost: 1.4635275 | Accuracy: 0.6000000\n",
            "Iter:   44 | Cost: 1.3334965 | Accuracy: 0.6000000\n",
            "Iter:   45 | Cost: 1.5324287 | Accuracy: 0.5000000\n",
            "Iter:   46 | Cost: 1.4768117 | Accuracy: 0.4750000\n",
            "Iter:   47 | Cost: 1.2599610 | Accuracy: 0.4750000\n",
            "Iter:   48 | Cost: 1.3537288 | Accuracy: 0.5000000\n",
            "Iter:   49 | Cost: 1.1367236 | Accuracy: 0.5500000\n",
            "Iter:   50 | Cost: 1.1696470 | Accuracy: 0.5500000\n",
            "Iter:   51 | Cost: 1.6597732 | Accuracy: 0.5000000\n",
            "Iter:   52 | Cost: 1.0734593 | Accuracy: 0.5000000\n",
            "Iter:   53 | Cost: 0.9473572 | Accuracy: 0.5250000\n",
            "Iter:   54 | Cost: 1.3302243 | Accuracy: 0.5000000\n",
            "Iter:   55 | Cost: 2.1127467 | Accuracy: 0.5000000\n",
            "Iter:   56 | Cost: 1.2438244 | Accuracy: 0.3750000\n",
            "Iter:   57 | Cost: 1.0891585 | Accuracy: 0.5000000\n",
            "Iter:   58 | Cost: 0.9982628 | Accuracy: 0.5000000\n",
            "Iter:   59 | Cost: 0.9767206 | Accuracy: 0.6500000\n",
            "Iter:   60 | Cost: 0.2464592 | Accuracy: 0.9500000\n",
            "Iter:   61 | Cost: 0.3989727 | Accuracy: 0.8500000\n",
            "Iter:   62 | Cost: 0.4716261 | Accuracy: 0.8000000\n",
            "Iter:   63 | Cost: 0.8644093 | Accuracy: 0.6000000\n",
            "Iter:   64 | Cost: 1.3599208 | Accuracy: 0.5000000\n",
            "Iter:   65 | Cost: 1.6933104 | Accuracy: 0.5000000\n",
            "Iter:   66 | Cost: 1.7759825 | Accuracy: 0.5000000\n",
            "Iter:   67 | Cost: 1.2017496 | Accuracy: 0.5000000\n",
            "Iter:   68 | Cost: 1.0993244 | Accuracy: 0.4000000\n",
            "Iter:   69 | Cost: 1.0250935 | Accuracy: 0.5000000\n",
            "Iter:   70 | Cost: 0.4867712 | Accuracy: 0.8750000\n",
            "Iter:   71 | Cost: 0.2443021 | Accuracy: 1.0000000\n",
            "Iter:   72 | Cost: 0.0713442 | Accuracy: 1.0000000\n",
            "Iter:   73 | Cost: 0.0895383 | Accuracy: 1.0000000\n",
            "Iter:   74 | Cost: 0.1419925 | Accuracy: 1.0000000\n",
            "Iter:   75 | Cost: 0.2101414 | Accuracy: 1.0000000\n",
            "Iter:   76 | Cost: 0.0210466 | Accuracy: 1.0000000\n",
            "Iter:   77 | Cost: 0.0048848 | Accuracy: 1.0000000\n",
            "Iter:   78 | Cost: 0.0117645 | Accuracy: 1.0000000\n",
            "Iter:   79 | Cost: 0.0257630 | Accuracy: 1.0000000\n",
            "Iter:   80 | Cost: 0.0180148 | Accuracy: 1.0000000\n",
            "Iter:   81 | Cost: 0.0127987 | Accuracy: 1.0000000\n",
            "Iter:   82 | Cost: 0.0175121 | Accuracy: 1.0000000\n",
            "Iter:   83 | Cost: 0.0056103 | Accuracy: 1.0000000\n",
            "Iter:   84 | Cost: 0.0037080 | Accuracy: 1.0000000\n",
            "Iter:   85 | Cost: 0.0025099 | Accuracy: 1.0000000\n",
            "Iter:   86 | Cost: 0.0021568 | Accuracy: 1.0000000\n",
            "Iter:   87 | Cost: 0.0032032 | Accuracy: 1.0000000\n",
            "Iter:   88 | Cost: 0.0024646 | Accuracy: 1.0000000\n",
            "Iter:   89 | Cost: 0.0028452 | Accuracy: 1.0000000\n",
            "Iter:   90 | Cost: 0.0028308 | Accuracy: 1.0000000\n",
            "Iter:   91 | Cost: 0.0025190 | Accuracy: 1.0000000\n",
            "Iter:   92 | Cost: 0.0022221 | Accuracy: 1.0000000\n",
            "Iter:   93 | Cost: 0.0034567 | Accuracy: 1.0000000\n",
            "Iter:   94 | Cost: 0.0014389 | Accuracy: 1.0000000\n",
            "Iter:   95 | Cost: 0.0011706 | Accuracy: 1.0000000\n",
            "Iter:   96 | Cost: 0.0010117 | Accuracy: 1.0000000\n",
            "Iter:   97 | Cost: 0.0010197 | Accuracy: 1.0000000\n",
            "Iter:   98 | Cost: 0.0009185 | Accuracy: 1.0000000\n",
            "Iter:   99 | Cost: 0.0011736 | Accuracy: 1.0000000\n",
            "Iter:  100 | Cost: 0.0007797 | Accuracy: 1.0000000\n",
            "x = [0.9879638  1.04024352 0.03505779], y = -1, pred=-1.0\n",
            "x = [ 0.00822142 -0.01371639  0.02754764], y = -1, pred=-1.0\n",
            "x = [0.99295538 0.0185414  0.98787918], y = -1, pred=-1.0\n",
            "x = [1.05597339 1.0324364  0.00341346], y = -1, pred=-1.0\n",
            "x = [-0.02495464  0.01131329 -0.01545709], y = -1, pred=-1.0\n",
            "x = [ 0.04865572 -0.02187662 -0.03744429], y = -1, pred=-1.0\n",
            "x = [-0.01112591  1.03013485  1.01654904], y = -1, pred=-1.0\n",
            "x = [1.02916993e+00 3.76678161e-04 1.01428079e+00], y = -1, pred=-1.0\n",
            "x = [0.0102292 0.9922424 1.0334223], y = -1, pred=-1.0\n",
            "x = [ 0.03568738  0.04515961 -0.00036212], y = -1, pred=-1.0\n",
            "x = [ 1.01488301 -0.03164158 -0.02451988], y = 1, pred=1.0\n",
            "x = [0.00228088 1.02398959 0.00108919], y = 1, pred=1.0\n",
            "x = [-0.00994703  0.95064989  0.01347249], y = 1, pred=1.0\n",
            "x = [ 0.91944514 -0.04143044 -0.04457641], y = 1, pred=1.0\n",
            "x = [ 1.02296955e+00 -2.51826060e-05 -2.33469569e-02], y = 1, pred=1.0\n",
            "x = [0.04621937 0.97989627 0.02453764], y = 1, pred=1.0\n",
            "x = [ 0.02340046  0.9897321  -0.01949139], y = 1, pred=1.0\n",
            "x = [0.0433125  1.01162301 0.02526416], y = 1, pred=1.0\n",
            "x = [0.95832342 1.01347606 0.98019078], y = 1, pred=1.0\n",
            "x = [ 9.69991074e-01 -1.46136162e-02 -9.48020333e-04], y = 1, pred=1.0\n",
            "Accuracy on unseen data: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ερώτημα 3"
      ],
      "metadata": {
        "id": "663OI8XRTFjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    return pd.read_csv(file_path, sep='\\t', header=None)\n",
        "\n",
        "# Load the training and testing data\n",
        "classA_train = load_data(\"/content/gdrive/My Drive/classA_train_N5.dat\")\n",
        "classB_train = load_data(\"/content/gdrive/My Drive/classB_train_N5.dat\")\n",
        "classA_test = load_data(\"/content/gdrive/My Drive/classA_test_N5.dat\")\n",
        "classB_test = load_data(\"/content/gdrive/My Drive/classB_test_N5.dat\")\n",
        "\n",
        "# Label the data\n",
        "classA_train['Label'] = 0\n",
        "classB_train['Label'] = 1\n",
        "classA_test['Label'] = 0\n",
        "classB_test['Label'] = 1\n",
        "\n",
        "df = pd.DataFrame(classA_train)\n",
        "\n",
        "featuresA= df[[0, 1, 2,3,4]].to_numpy()\n",
        "\n",
        "featuresA.shape\n",
        "\n",
        "df = pd.DataFrame(classB_train)\n",
        "\n",
        "featuresB = df[[0, 1, 2,3,4]].to_numpy()\n",
        "\n",
        "featuresB.shape\n",
        "\n",
        "df = pd.DataFrame(classA_train)\n",
        "\n",
        "labelsA = df['Label'].to_numpy()\n",
        "\n",
        "labelsA.shape\n",
        "\n",
        "\n",
        "df = pd.DataFrame(classB_train)\n",
        "\n",
        "labelsB = df['Label'].to_numpy()\n",
        "featuresB.shape\n",
        "\n",
        "df = pd.DataFrame(classA_test)\n",
        "\n",
        "featuresAT= df[[0, 1, 2,3,4]].to_numpy()\n",
        "\n",
        "featuresA.shape\n",
        "\n",
        "df = pd.DataFrame(classB_test)\n",
        "\n",
        "featuresBT = df[[0, 1, 2,3,4]].to_numpy()\n",
        "\n",
        "featuresB.shape\n",
        "\n",
        "\n",
        "df = pd.DataFrame(classA_test)\n",
        "\n",
        "labelsAT = df['Label'].to_numpy()\n",
        "\n",
        "labelsA.shape\n",
        "\n",
        "\n",
        "df = pd.DataFrame(classB_test)\n",
        "\n",
        "labelsBT = df['Label'].to_numpy()\n",
        "\n",
        "labelsB.shape\n",
        "\n",
        "train_data = np.concatenate((featuresA, featuresB), axis=0)\n",
        "train_labels = np.concatenate((labelsA, labelsB), axis=0)\n",
        "test_data = np.concatenate((featuresAT, featuresBT), axis=0)\n",
        "test_labels = np.concatenate((labelsAT, labelsBT), axis=0)"
      ],
      "metadata": {
        "id": "5YVVAkayTdkV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import NesterovMomentumOptimizer\n",
        "\n",
        "# Quantum device with five qubits\n",
        "dev = qml.device(\"lightning.qubit\", wires=5)\n",
        "\n",
        "def layer(layer_weights):\n",
        "    # Arbitrary rotation on each of the five qubits\n",
        "    for wire in range(5):\n",
        "        qml.Rot(*layer_weights[wire], wires=wire)\n",
        "\n",
        "    # Ring of CNOTs for entanglement across all five qubits\n",
        "    for wire_pair in ([0, 1], [1, 2], [2, 3], [3,4], [4,0]):\n",
        "        qml.CNOT(wires=wire_pair)\n",
        "\n",
        "def state_preparation(x):\n",
        "    # Applying rotations based on the input x to each qubit\n",
        "    for i, value in enumerate(x):\n",
        "        qml.RY(np.pi * value, wires=i)\n",
        "\n",
        "\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, x):\n",
        "    state_preparation(x)\n",
        "    for layer_weights in weights:\n",
        "        layer(layer_weights)\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias\n",
        "\n",
        "# Accuracy metric\n",
        "def accuracy(labels, predictions):\n",
        "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
        "    return acc / len(labels)\n",
        "\n",
        "def square_loss(labels, predictions):\n",
        "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
        "\n",
        "# Cost function\n",
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)\n",
        "\n",
        "X_train, Y_train = train_data, train_labels\n",
        "Y_train = Y_train * 2 - 1\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "num_qubits = 5\n",
        "num_layers = 2\n",
        "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3)\n",
        "bias_init = np.array(0.0)\n",
        "\n",
        "opt = NesterovMomentumOptimizer(0.5)\n",
        "batch_size = 5\n",
        "\n",
        "weights = weights_init\n",
        "bias = bias_init\n",
        "for it in range(100):\n",
        "    # Update weights and bias using optimizer\n",
        "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "    X_batch = X_train[batch_index]\n",
        "    Y_batch = Y_train[batch_index]\n",
        "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n",
        "\n",
        "    # Compute predictions for the entire training set\n",
        "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_train]\n",
        "    current_cost = cost(weights, bias, X_train, Y_train)\n",
        "    acc = accuracy(Y_train, predictions)\n",
        "\n",
        "    print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")\n",
        "\n",
        "\n",
        "X_test = test_data\n",
        "Y_test = test_labels\n",
        "Y_test = Y_test * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
        "\n",
        "predictions_test = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
        "\n",
        "for x,y,p in zip(X_test, Y_test, predictions_test):\n",
        "    print(f\"x = {x}, y = {y}, pred={p}\")\n",
        "\n",
        "acc_test = accuracy(Y_test, predictions_test)\n",
        "print(\"Accuracy on unseen data:\", acc_test)\n",
        "\n",
        "\n",
        "X_test = test_data\n",
        "Y_test = test_labels\n",
        "Y_test = Y_test * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
        "\n",
        "predictions_test = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
        "\n",
        "for x,y,p in zip(X_test, Y_test, predictions_test):\n",
        "    print(f\"x = {x}, y = {y}, pred={p}\")\n",
        "\n",
        "acc_test = accuracy(Y_test, predictions_test)\n",
        "print(\"Accuracy on unseen data:\", acc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw1NhsCdTLQB",
        "outputId": "46ff1450-d14f-4f20-cc6d-ce7fafb8bb44"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter:    1 | Cost: 2.1210660 | Accuracy: 0.4937500\n",
            "Iter:    2 | Cost: 2.1826482 | Accuracy: 0.4937500\n",
            "Iter:    3 | Cost: 1.8840404 | Accuracy: 0.4937500\n",
            "Iter:    4 | Cost: 2.0003586 | Accuracy: 0.5187500\n",
            "Iter:    5 | Cost: 0.8405804 | Accuracy: 0.7375000\n",
            "Iter:    6 | Cost: 0.9764800 | Accuracy: 0.5000000\n",
            "Iter:    7 | Cost: 1.0291325 | Accuracy: 0.5000000\n",
            "Iter:    8 | Cost: 0.7725324 | Accuracy: 0.7000000\n",
            "Iter:    9 | Cost: 0.9725371 | Accuracy: 0.7312500\n",
            "Iter:   10 | Cost: 1.6241802 | Accuracy: 0.5000000\n",
            "Iter:   11 | Cost: 0.8584280 | Accuracy: 0.5625000\n",
            "Iter:   12 | Cost: 1.1960367 | Accuracy: 0.5000000\n",
            "Iter:   13 | Cost: 1.0155524 | Accuracy: 0.5062500\n",
            "Iter:   14 | Cost: 1.1199128 | Accuracy: 0.5000000\n",
            "Iter:   15 | Cost: 0.7510164 | Accuracy: 0.7625000\n",
            "Iter:   16 | Cost: 0.4979719 | Accuracy: 0.8062500\n",
            "Iter:   17 | Cost: 0.3484327 | Accuracy: 0.9062500\n",
            "Iter:   18 | Cost: 0.2514139 | Accuracy: 1.0000000\n",
            "Iter:   19 | Cost: 0.1266786 | Accuracy: 1.0000000\n",
            "Iter:   20 | Cost: 0.0243685 | Accuracy: 1.0000000\n",
            "Iter:   21 | Cost: 0.0228056 | Accuracy: 1.0000000\n",
            "Iter:   22 | Cost: 0.0540421 | Accuracy: 1.0000000\n",
            "Iter:   23 | Cost: 0.0762200 | Accuracy: 1.0000000\n",
            "Iter:   24 | Cost: 0.0674828 | Accuracy: 1.0000000\n",
            "Iter:   25 | Cost: 0.0340402 | Accuracy: 1.0000000\n",
            "Iter:   26 | Cost: 0.0174912 | Accuracy: 1.0000000\n",
            "Iter:   27 | Cost: 0.0073072 | Accuracy: 1.0000000\n",
            "Iter:   28 | Cost: 0.0052388 | Accuracy: 1.0000000\n",
            "Iter:   29 | Cost: 0.0075873 | Accuracy: 1.0000000\n",
            "Iter:   30 | Cost: 0.0043948 | Accuracy: 1.0000000\n",
            "Iter:   31 | Cost: 0.0018879 | Accuracy: 1.0000000\n",
            "Iter:   32 | Cost: 0.0023219 | Accuracy: 1.0000000\n",
            "Iter:   33 | Cost: 0.0027313 | Accuracy: 1.0000000\n",
            "Iter:   34 | Cost: 0.0051936 | Accuracy: 1.0000000\n",
            "Iter:   35 | Cost: 0.0040541 | Accuracy: 1.0000000\n",
            "Iter:   36 | Cost: 0.0034901 | Accuracy: 1.0000000\n",
            "Iter:   37 | Cost: 0.0025782 | Accuracy: 1.0000000\n",
            "Iter:   38 | Cost: 0.0021725 | Accuracy: 1.0000000\n",
            "Iter:   39 | Cost: 0.0013051 | Accuracy: 1.0000000\n",
            "Iter:   40 | Cost: 0.0007440 | Accuracy: 1.0000000\n",
            "Iter:   41 | Cost: 0.0005706 | Accuracy: 1.0000000\n",
            "Iter:   42 | Cost: 0.0003691 | Accuracy: 1.0000000\n",
            "Iter:   43 | Cost: 0.0002987 | Accuracy: 1.0000000\n",
            "Iter:   44 | Cost: 0.0003310 | Accuracy: 1.0000000\n",
            "Iter:   45 | Cost: 0.0002753 | Accuracy: 1.0000000\n",
            "Iter:   46 | Cost: 0.0003370 | Accuracy: 1.0000000\n",
            "Iter:   47 | Cost: 0.0003388 | Accuracy: 1.0000000\n",
            "Iter:   48 | Cost: 0.0004997 | Accuracy: 1.0000000\n",
            "Iter:   49 | Cost: 0.0005770 | Accuracy: 1.0000000\n",
            "Iter:   50 | Cost: 0.0004654 | Accuracy: 1.0000000\n",
            "Iter:   51 | Cost: 0.0005977 | Accuracy: 1.0000000\n",
            "Iter:   52 | Cost: 0.0005501 | Accuracy: 1.0000000\n",
            "Iter:   53 | Cost: 0.0005299 | Accuracy: 1.0000000\n",
            "Iter:   54 | Cost: 0.0004878 | Accuracy: 1.0000000\n",
            "Iter:   55 | Cost: 0.0005439 | Accuracy: 1.0000000\n",
            "Iter:   56 | Cost: 0.0003884 | Accuracy: 1.0000000\n",
            "Iter:   57 | Cost: 0.0004558 | Accuracy: 1.0000000\n",
            "Iter:   58 | Cost: 0.0003147 | Accuracy: 1.0000000\n",
            "Iter:   59 | Cost: 0.0002804 | Accuracy: 1.0000000\n",
            "Iter:   60 | Cost: 0.0002648 | Accuracy: 1.0000000\n",
            "Iter:   61 | Cost: 0.0003050 | Accuracy: 1.0000000\n",
            "Iter:   62 | Cost: 0.0001963 | Accuracy: 1.0000000\n",
            "Iter:   63 | Cost: 0.0001751 | Accuracy: 1.0000000\n",
            "Iter:   64 | Cost: 0.0001915 | Accuracy: 1.0000000\n",
            "Iter:   65 | Cost: 0.0002500 | Accuracy: 1.0000000\n",
            "Iter:   66 | Cost: 0.0001475 | Accuracy: 1.0000000\n",
            "Iter:   67 | Cost: 0.0002484 | Accuracy: 1.0000000\n",
            "Iter:   68 | Cost: 0.0001433 | Accuracy: 1.0000000\n",
            "Iter:   69 | Cost: 0.0001316 | Accuracy: 1.0000000\n",
            "Iter:   70 | Cost: 0.0001380 | Accuracy: 1.0000000\n",
            "Iter:   71 | Cost: 0.0001802 | Accuracy: 1.0000000\n",
            "Iter:   72 | Cost: 0.0001701 | Accuracy: 1.0000000\n",
            "Iter:   73 | Cost: 0.0002221 | Accuracy: 1.0000000\n",
            "Iter:   74 | Cost: 0.0001983 | Accuracy: 1.0000000\n",
            "Iter:   75 | Cost: 0.0001513 | Accuracy: 1.0000000\n",
            "Iter:   76 | Cost: 0.0001937 | Accuracy: 1.0000000\n",
            "Iter:   77 | Cost: 0.0001512 | Accuracy: 1.0000000\n",
            "Iter:   78 | Cost: 0.0001632 | Accuracy: 1.0000000\n",
            "Iter:   79 | Cost: 0.0001476 | Accuracy: 1.0000000\n",
            "Iter:   80 | Cost: 0.0001464 | Accuracy: 1.0000000\n",
            "Iter:   81 | Cost: 0.0001578 | Accuracy: 1.0000000\n",
            "Iter:   82 | Cost: 0.0001416 | Accuracy: 1.0000000\n",
            "Iter:   83 | Cost: 0.0001421 | Accuracy: 1.0000000\n",
            "Iter:   84 | Cost: 0.0002828 | Accuracy: 1.0000000\n",
            "Iter:   85 | Cost: 0.0001370 | Accuracy: 1.0000000\n",
            "Iter:   86 | Cost: 0.0001359 | Accuracy: 1.0000000\n",
            "Iter:   87 | Cost: 0.0002070 | Accuracy: 1.0000000\n",
            "Iter:   88 | Cost: 0.0002032 | Accuracy: 1.0000000\n",
            "Iter:   89 | Cost: 0.0001523 | Accuracy: 1.0000000\n",
            "Iter:   90 | Cost: 0.0001392 | Accuracy: 1.0000000\n",
            "Iter:   91 | Cost: 0.0001613 | Accuracy: 1.0000000\n",
            "Iter:   92 | Cost: 0.0001668 | Accuracy: 1.0000000\n",
            "Iter:   93 | Cost: 0.0001754 | Accuracy: 1.0000000\n",
            "Iter:   94 | Cost: 0.0001375 | Accuracy: 1.0000000\n",
            "Iter:   95 | Cost: 0.0001493 | Accuracy: 1.0000000\n",
            "Iter:   96 | Cost: 0.0002775 | Accuracy: 1.0000000\n",
            "Iter:   97 | Cost: 0.0001322 | Accuracy: 1.0000000\n",
            "Iter:   98 | Cost: 0.0001362 | Accuracy: 1.0000000\n",
            "Iter:   99 | Cost: 0.0001894 | Accuracy: 1.0000000\n",
            "Iter:  100 | Cost: 0.0001335 | Accuracy: 1.0000000\n",
            "x = [ 1.00078051e+00  1.00960572e+00 -9.13973821e-04  1.01791772e+00\n",
            "  1.02871204e+00], y = -1, pred=-1.0\n",
            "x = [1.02412767 0.99765243 0.9965522  1.0127529  0.01685508], y = -1, pred=-1.0\n",
            "x = [0.01146496 0.00558623 0.97068373 1.01640891 0.0035931 ], y = -1, pred=-1.0\n",
            "x = [9.82287993e-01 9.84790026e-01 1.03185392e+00 1.01959629e+00\n",
            " 1.75286700e-04], y = -1, pred=-1.0\n",
            "x = [-0.0091527   0.98941855  0.99440876  0.0015865   0.01958929], y = -1, pred=-1.0\n",
            "x = [-0.0202636   0.03758615  1.00291274  0.00681475  1.01508888], y = -1, pred=-1.0\n",
            "x = [ 0.99377346  1.01146153 -0.03502341 -0.00977428  0.01278234], y = -1, pred=-1.0\n",
            "x = [ 0.02021368 -0.00492514  1.00697758 -0.04591131  0.98195489], y = -1, pred=-1.0\n",
            "x = [1.00043345 1.01962107 0.00373615 1.00475642 0.98050153], y = -1, pred=-1.0\n",
            "x = [ 1.00927741  0.01671144  0.99485023  0.03678372 -0.01330865], y = -1, pred=-1.0\n",
            "x = [1.01694026 0.02027979 0.03689011 1.0041608  0.01244388], y = -1, pred=-1.0\n",
            "x = [1.00676982 0.99819512 1.01913702 0.00373949 0.99865417], y = -1, pred=-1.0\n",
            "x = [ 0.02328575  0.99108301  0.01688198 -0.01107108  0.99601293], y = -1, pred=-1.0\n",
            "x = [0.01823229 1.01132879 1.0163664  0.99793635 0.97933871], y = -1, pred=-1.0\n",
            "x = [0.024577   1.0100511  0.98587354 0.00810354 0.00537528], y = -1, pred=-1.0\n",
            "x = [ 1.0079189  -0.01856428  0.0355069  -0.00476513  0.99327562], y = -1, pred=-1.0\n",
            "x = [ 0.96266806 -0.00378435 -0.01144543 -0.01282539  1.02030586], y = -1, pred=-1.0\n",
            "x = [ 0.0252498   0.02122599 -0.01773163  1.0211777   1.00563238], y = -1, pred=-1.0\n",
            "x = [-0.02045272  0.97965642 -0.02483943  0.99043769 -0.00919207], y = -1, pred=-1.0\n",
            "x = [0.01312579 0.98840339 0.01322351 0.00202718 0.98931388], y = -1, pred=-1.0\n",
            "x = [ 0.98630323 -0.0154717   0.99099859 -0.00606217  0.00597969], y = -1, pred=-1.0\n",
            "x = [0.02592993 1.01578125 0.98869771 0.01384814 0.02911793], y = -1, pred=-1.0\n",
            "x = [ 1.00799530e+00  9.66369325e-03 -4.52120159e-03 -4.06378155e-04\n",
            "  9.93259988e-01], y = -1, pred=-1.0\n",
            "x = [-0.00491293  0.00784065  1.01000514  0.97025605  0.00463925], y = -1, pred=-1.0\n",
            "x = [-0.0305568   0.96980687  0.00616405 -0.02157819  1.04047349], y = -1, pred=-1.0\n",
            "x = [ 1.00379639  0.99427967  1.00097012  1.0208104  -0.02917157], y = -1, pred=-1.0\n",
            "x = [-5.46122385e-02  9.80093945e-01  9.98060819e-01  4.64952280e-04\n",
            "  1.69519286e-02], y = -1, pred=-1.0\n",
            "x = [ 0.99274296 -0.00638804  1.0043986   1.0339537   0.95998894], y = -1, pred=-1.0\n",
            "x = [ 1.02455288  0.02180877  0.01363868  0.99519059 -0.01818993], y = -1, pred=-1.0\n",
            "x = [1.00377839 0.0421892  0.9866629  1.00980898 1.03268948], y = -1, pred=-1.0\n",
            "x = [9.67093677e-01 1.23339885e-02 9.75820911e-01 1.00159458e+00\n",
            " 5.39516773e-05], y = 1, pred=1.0\n",
            "x = [-0.033271    1.00086254 -0.01480546  0.01142205 -0.01745604], y = 1, pred=1.0\n",
            "x = [-0.01727313  1.03721408  1.0006458   0.99471866 -0.03002861], y = 1, pred=1.0\n",
            "x = [ 0.99640507  0.02676504  0.04685204 -0.01579599 -0.01296158], y = 1, pred=1.0\n",
            "x = [0.9761303  1.00583688 0.98898269 0.01363323 0.00794281], y = 1, pred=1.0\n",
            "x = [ 0.00931268  0.97160617  1.03826511 -0.03229427  0.9769523 ], y = 1, pred=1.0\n",
            "x = [ 1.0172572  -0.0098452   1.00116537  0.97644576  0.02831976], y = 1, pred=1.0\n",
            "x = [0.98861421 1.02078968 0.96819562 0.99930625 0.96582843], y = 1, pred=1.0\n",
            "x = [ 0.00577263 -0.00899575  0.00809414  1.00487495  0.00190581], y = 1, pred=1.0\n",
            "x = [-0.03050383  0.02871864  1.0285405   1.01545878  0.98078481], y = 1, pred=1.0\n",
            "x = [ 0.9875409   0.00708216  0.01570466 -0.00875315 -0.01552055], y = 1, pred=1.0\n",
            "x = [-0.01267565  1.00227375  1.02360123  1.05069128  0.01480752], y = 1, pred=1.0\n",
            "x = [ 1.00221605  0.98708144  0.98670609 -0.00708419  0.02271034], y = 1, pred=1.0\n",
            "x = [0.99024198 0.03437719 0.02049218 1.03499663 0.99337511], y = 1, pred=1.0\n",
            "x = [ 9.88957921e-01 -2.82629634e-02 -8.03162776e-03  1.57389498e-03\n",
            " -7.35043514e-04], y = 1, pred=1.0\n",
            "x = [0.98962709 1.01524742 0.00178693 1.03459525 0.03326632], y = 1, pred=1.0\n",
            "x = [ 0.01496434  0.00508076 -0.02667086 -0.02302309  1.00285749], y = 1, pred=1.0\n",
            "x = [ 1.00211729  1.01637119  1.0065577   0.02405759 -0.00662425], y = 1, pred=1.0\n",
            "x = [-0.01675407  0.03801995 -0.03795998 -0.0401761   0.97072154], y = 1, pred=1.0\n",
            "x = [-0.00356208  1.03121394  1.01738851  0.00679314  1.00433078], y = 1, pred=1.0\n",
            "x = [0.94025544 1.00351804 0.98153662 0.04292429 0.0155459 ], y = 1, pred=1.0\n",
            "x = [0.00141179 0.97560123 0.01824098 1.0002047  0.98337889], y = 1, pred=1.0\n",
            "x = [-0.01692522  1.00159153  0.02970102  0.99069714  1.0007761 ], y = 1, pred=1.0\n",
            "x = [ 1.00510916 -0.01405833  1.01406153  0.99160256 -0.0215212 ], y = 1, pred=1.0\n",
            "x = [0.98245655 0.97467976 0.97284582 0.98668116 1.01854355], y = 1, pred=1.0\n",
            "x = [1.00266923e+00 1.27674105e-02 3.80280910e-04 8.16147369e-03\n",
            " 1.43220834e-02], y = 1, pred=1.0\n",
            "x = [ 0.00484486 -0.03361341 -0.00145799  0.02154224  1.00535577], y = 1, pred=1.0\n",
            "x = [ 0.04393967  0.99055808 -0.04416058  0.0252595   0.02187214], y = 1, pred=1.0\n",
            "x = [ 0.99671274 -0.03006504  0.02651744  1.00808864  0.99992915], y = 1, pred=1.0\n",
            "x = [1.00509841 1.0194048  0.96040693 0.99516679 0.98742323], y = 1, pred=1.0\n",
            "Accuracy on unseen data: 1.0\n",
            "x = [ 1.00078051e+00  1.00960572e+00 -9.13973821e-04  1.01791772e+00\n",
            "  1.02871204e+00], y = -1, pred=-1.0\n",
            "x = [1.02412767 0.99765243 0.9965522  1.0127529  0.01685508], y = -1, pred=-1.0\n",
            "x = [0.01146496 0.00558623 0.97068373 1.01640891 0.0035931 ], y = -1, pred=-1.0\n",
            "x = [9.82287993e-01 9.84790026e-01 1.03185392e+00 1.01959629e+00\n",
            " 1.75286700e-04], y = -1, pred=-1.0\n",
            "x = [-0.0091527   0.98941855  0.99440876  0.0015865   0.01958929], y = -1, pred=-1.0\n",
            "x = [-0.0202636   0.03758615  1.00291274  0.00681475  1.01508888], y = -1, pred=-1.0\n",
            "x = [ 0.99377346  1.01146153 -0.03502341 -0.00977428  0.01278234], y = -1, pred=-1.0\n",
            "x = [ 0.02021368 -0.00492514  1.00697758 -0.04591131  0.98195489], y = -1, pred=-1.0\n",
            "x = [1.00043345 1.01962107 0.00373615 1.00475642 0.98050153], y = -1, pred=-1.0\n",
            "x = [ 1.00927741  0.01671144  0.99485023  0.03678372 -0.01330865], y = -1, pred=-1.0\n",
            "x = [1.01694026 0.02027979 0.03689011 1.0041608  0.01244388], y = -1, pred=-1.0\n",
            "x = [1.00676982 0.99819512 1.01913702 0.00373949 0.99865417], y = -1, pred=-1.0\n",
            "x = [ 0.02328575  0.99108301  0.01688198 -0.01107108  0.99601293], y = -1, pred=-1.0\n",
            "x = [0.01823229 1.01132879 1.0163664  0.99793635 0.97933871], y = -1, pred=-1.0\n",
            "x = [0.024577   1.0100511  0.98587354 0.00810354 0.00537528], y = -1, pred=-1.0\n",
            "x = [ 1.0079189  -0.01856428  0.0355069  -0.00476513  0.99327562], y = -1, pred=-1.0\n",
            "x = [ 0.96266806 -0.00378435 -0.01144543 -0.01282539  1.02030586], y = -1, pred=-1.0\n",
            "x = [ 0.0252498   0.02122599 -0.01773163  1.0211777   1.00563238], y = -1, pred=-1.0\n",
            "x = [-0.02045272  0.97965642 -0.02483943  0.99043769 -0.00919207], y = -1, pred=-1.0\n",
            "x = [0.01312579 0.98840339 0.01322351 0.00202718 0.98931388], y = -1, pred=-1.0\n",
            "x = [ 0.98630323 -0.0154717   0.99099859 -0.00606217  0.00597969], y = -1, pred=-1.0\n",
            "x = [0.02592993 1.01578125 0.98869771 0.01384814 0.02911793], y = -1, pred=-1.0\n",
            "x = [ 1.00799530e+00  9.66369325e-03 -4.52120159e-03 -4.06378155e-04\n",
            "  9.93259988e-01], y = -1, pred=-1.0\n",
            "x = [-0.00491293  0.00784065  1.01000514  0.97025605  0.00463925], y = -1, pred=-1.0\n",
            "x = [-0.0305568   0.96980687  0.00616405 -0.02157819  1.04047349], y = -1, pred=-1.0\n",
            "x = [ 1.00379639  0.99427967  1.00097012  1.0208104  -0.02917157], y = -1, pred=-1.0\n",
            "x = [-5.46122385e-02  9.80093945e-01  9.98060819e-01  4.64952280e-04\n",
            "  1.69519286e-02], y = -1, pred=-1.0\n",
            "x = [ 0.99274296 -0.00638804  1.0043986   1.0339537   0.95998894], y = -1, pred=-1.0\n",
            "x = [ 1.02455288  0.02180877  0.01363868  0.99519059 -0.01818993], y = -1, pred=-1.0\n",
            "x = [1.00377839 0.0421892  0.9866629  1.00980898 1.03268948], y = -1, pred=-1.0\n",
            "x = [9.67093677e-01 1.23339885e-02 9.75820911e-01 1.00159458e+00\n",
            " 5.39516773e-05], y = 1, pred=1.0\n",
            "x = [-0.033271    1.00086254 -0.01480546  0.01142205 -0.01745604], y = 1, pred=1.0\n",
            "x = [-0.01727313  1.03721408  1.0006458   0.99471866 -0.03002861], y = 1, pred=1.0\n",
            "x = [ 0.99640507  0.02676504  0.04685204 -0.01579599 -0.01296158], y = 1, pred=1.0\n",
            "x = [0.9761303  1.00583688 0.98898269 0.01363323 0.00794281], y = 1, pred=1.0\n",
            "x = [ 0.00931268  0.97160617  1.03826511 -0.03229427  0.9769523 ], y = 1, pred=1.0\n",
            "x = [ 1.0172572  -0.0098452   1.00116537  0.97644576  0.02831976], y = 1, pred=1.0\n",
            "x = [0.98861421 1.02078968 0.96819562 0.99930625 0.96582843], y = 1, pred=1.0\n",
            "x = [ 0.00577263 -0.00899575  0.00809414  1.00487495  0.00190581], y = 1, pred=1.0\n",
            "x = [-0.03050383  0.02871864  1.0285405   1.01545878  0.98078481], y = 1, pred=1.0\n",
            "x = [ 0.9875409   0.00708216  0.01570466 -0.00875315 -0.01552055], y = 1, pred=1.0\n",
            "x = [-0.01267565  1.00227375  1.02360123  1.05069128  0.01480752], y = 1, pred=1.0\n",
            "x = [ 1.00221605  0.98708144  0.98670609 -0.00708419  0.02271034], y = 1, pred=1.0\n",
            "x = [0.99024198 0.03437719 0.02049218 1.03499663 0.99337511], y = 1, pred=1.0\n",
            "x = [ 9.88957921e-01 -2.82629634e-02 -8.03162776e-03  1.57389498e-03\n",
            " -7.35043514e-04], y = 1, pred=1.0\n",
            "x = [0.98962709 1.01524742 0.00178693 1.03459525 0.03326632], y = 1, pred=1.0\n",
            "x = [ 0.01496434  0.00508076 -0.02667086 -0.02302309  1.00285749], y = 1, pred=1.0\n",
            "x = [ 1.00211729  1.01637119  1.0065577   0.02405759 -0.00662425], y = 1, pred=1.0\n",
            "x = [-0.01675407  0.03801995 -0.03795998 -0.0401761   0.97072154], y = 1, pred=1.0\n",
            "x = [-0.00356208  1.03121394  1.01738851  0.00679314  1.00433078], y = 1, pred=1.0\n",
            "x = [0.94025544 1.00351804 0.98153662 0.04292429 0.0155459 ], y = 1, pred=1.0\n",
            "x = [0.00141179 0.97560123 0.01824098 1.0002047  0.98337889], y = 1, pred=1.0\n",
            "x = [-0.01692522  1.00159153  0.02970102  0.99069714  1.0007761 ], y = 1, pred=1.0\n",
            "x = [ 1.00510916 -0.01405833  1.01406153  0.99160256 -0.0215212 ], y = 1, pred=1.0\n",
            "x = [0.98245655 0.97467976 0.97284582 0.98668116 1.01854355], y = 1, pred=1.0\n",
            "x = [1.00266923e+00 1.27674105e-02 3.80280910e-04 8.16147369e-03\n",
            " 1.43220834e-02], y = 1, pred=1.0\n",
            "x = [ 0.00484486 -0.03361341 -0.00145799  0.02154224  1.00535577], y = 1, pred=1.0\n",
            "x = [ 0.04393967  0.99055808 -0.04416058  0.0252595   0.02187214], y = 1, pred=1.0\n",
            "x = [ 0.99671274 -0.03006504  0.02651744  1.00808864  0.99992915], y = 1, pred=1.0\n",
            "x = [1.00509841 1.0194048  0.96040693 0.99516679 0.98742323], y = 1, pred=1.0\n",
            "Accuracy on unseen data: 1.0\n"
          ]
        }
      ]
    }
  ]
}